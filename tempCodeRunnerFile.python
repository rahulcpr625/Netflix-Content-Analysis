# recommender.py
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import linear_kernel

# Load dataset
df = pd.read_csv("netflix_titles.csv")

# Fill missing values
df['listed_in'] = df['listed_in'].fillna('')
df['description'] = df['description'].fillna('')
df['release_year'] = df['release_year'].fillna(0)

# Combine features for content similarity
df['combined_features'] = df['listed_in'] + ' ' + df['description']

# TF-IDF vectorization
tfidf = TfidfVectorizer(stop_words='english')
tfidf_matrix = tfidf.fit_transform(df['combined_features'])

# Cosine similarity
cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)

# Index mapping
indices = pd.Series(df.index, index=df['title']).drop_duplicates()

def get_content_recommendations(title, cosine_sim=cosine_sim):
    if title not in indices:
        return []
    idx = indices[title]
    sim_scores = list(enumerate(cosine_sim[idx]))
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)
    sim_scores = sim_scores[1:11]
    movie_indices = [i[0] for i in sim_scores]
    return df.iloc[movie_indices][['title', 'listed_in', 'release_year']]

# Add a fake popularity score
df['popularity_score'] = (df['release_year'] - df['release_year'].min()) / \
                         (df['release_year'].max() - df['release_year'].min())

def get_hybrid_recommendations(title, weight_content=0.7, weight_popularity=0.3):
    recs = get_content_recommendations(title)
    if len(recs) == 0:
        return []
    recs = recs.merge(df[['title', 'popularity_score']], on='title', how='left')
    recs['hybrid_score'] = weight_content * 1.0 + weight_popularity * recs['popularity_score']
    recs = recs.sort_values('hybrid_score', ascending=False)
    return recs.head(6).to_dict(orient='records')
